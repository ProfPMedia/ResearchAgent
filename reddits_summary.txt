RESEARCH:
The recent escalation in Israel is primarily attributed to a surprise attack launched by Hamas and Islamic Jihad from Gaza. They fired thousands of rockets, targeted Jewish communities, and took hostages. Israel responded with airstrikes and implemented measures such as cutting off electricity and fuel supplies to Gaza. The exact reasons for the attack are not entirely clear, but there has been a rise in violence between Israeli soldiers, settlers, and Palestinians in the West Bank. Some factors that may have contributed to the escalation include extreme religious nationalists within Israel's right-wing coalition government and potential Iranian involvement. The attack caught Israel off guard, leading to questions about intelligence failures and the government's ability to protect its civilians. The international response has largely condemned Hamas and expressed support for Israel's right to self-defense. Efforts are underway to de-escalate the situation, including the involvement of UN peacekeeping forces and mediation by Egypt.

Sources:
- [The Guardian](https://www.theguardian.com/world/2023/oct/08/israel-hamas-gaza-palestinian-territories)
- [Amnesty International](https://www.amnesty.org/en/latest/news/2023/10/israel-opt-civilians-on-both-sides-paying-the-price-of-unprecedented-escalation-in-hostilities-between-israel-and-gaza-as-death-toll-mounts/)
- [CNN](https://www.cnn.com/2023/10/07/middleeast/sirens-israel-rocket-attack-gaza-intl-hnk/index.html)

HOT/TOP Reddit Posts:
[{"subreddit": "datasets", "id": "173rxw1", "url": "https://www.reddit.com/r/datasets/comments/173rxw1/are_there_any_cool_geology_datasets/", "title": "Are there any cool geology datasets?", "post": "I need help finding a dataset concerning geology that I can do my project over. I am taking a rudimentary geology lab and I have a final project where all I need is to discuss a cool geologic finding. I am a stats major and want to use my skills to better this project and potentially add to my resume. \n\nDoes anybody have any cool datasets or even topics I should research that I can potentially use for my project? I don\u2019t have a big background on geology but I\u2019m confident enough in my data analysis skills to help me by.", "c_cnt": 8}, {"subreddit": "datasets", "id": "173boxh", "url": "https://www.reddit.com/r/datasets/comments/173boxh/rgent_help_needed_unable_to_access_dataset_on/", "title": "rgent Help Needed: Unable to Access Dataset on Answer ALS Data Portal Due to Site Error", "post": "Hello everyone,\r  \n\r  \nWe are currently working on a crucial project that requires access to a specific dataset available on the Answer ALS Data Portal. However, we have encountered an error on the website which is preventing us from accessing the dataset. We have attempted to contact the administrators through the provided email address, but unfortunately, we have not received any response so far.\r  \n\r  \nWe are reaching out to this community in hopes that someone might have the required dataset or can assist us in procuring it. The dataset is critical for our ongoing research, and any help would be greatly appreciated.\r  \n\r  \nIf you have access to the dataset or know of any alternative way to obtain it, please feel free to reach out. We are willing to discuss any necessary arrangements or collaborations that can help us move forward with our project.\r  \n\r  \nThank you in advance for your assistance and understanding. Your help could significantly contribute to the progress of our research.\r  \n\r  \nhttps://dataportal.answerals.org/request-access", "c_cnt": 0}, {"subreddit": "datasets", "id": "173bov0", "url": "https://www.reddit.com/r/datasets/comments/173bov0/rgent_help_needed_unable_to_access_dataset_on/", "title": "rgent Help Needed: Unable to Access Dataset on Answer ALS Data Portal Due to Site Error", "post": "Hello everyone,\r  \n\r  \nWe are currently working on a crucial project that requires access to a specific dataset available on the Answer ALS Data Portal. However, we have encountered an error on the website which is preventing us from accessing the dataset. We have attempted to contact the administrators through the provided email address, but unfortunately, we have not received any response so far.\r  \n\r  \nWe are reaching out to this community in hopes that someone might have the required dataset or can assist us in procuring it. The dataset is critical for our ongoing research, and any help would be greatly appreciated.\r  \n\r  \nIf you have access to the dataset or know of any alternative way to obtain it, please feel free to reach out. We are willing to discuss any necessary arrangements or collaborations that can help us move forward with our project.\r  \n\r  \nThank you in advance for your assistance and understanding. Your help could significantly contribute to the progress of our research.\r  \n\r  \nhttps://dataportal.answerals.org/request-access", "c_cnt": 0}, {"subreddit": "datasets", "id": "17305ij", "url": "https://www.reddit.com/r/datasets/comments/17305ij/need_help_finding_dataset_for_slr_and_mlr_project/", "title": "Need Help Finding Dataset for SLR and MLR project", "post": "I am taking a regression analysis course this semester. We have a project to do simple linear regression analysis on a data set and in a few weeks another project to do multiple linear regression analysis.\n\nI\u2019ve been searching online for a good data set that I could use for both my SLR and MLR projects. Does anyone have any recommendations on where I could find a data set that I could use?", "c_cnt": 1}, {"subreddit": "datasets", "id": "172wynv", "url": "https://www.reddit.com/r/datasets/comments/172wynv/best_graph_to_visualize_a_dataset_where/", "title": "Best graph to visualize a dataset where respondents have to choose 3 things out of a list", "post": "Not sure if this is the right place to ask this.. but anyways\n\nI'm working on a report that presents and analyzes survey results.\n\nOne of the survey questions requires of the respondent to pick 3 things out of a list. What type of graph on excel would best illustrate this? I've been using horizontal and vertical bar graphs, but those were for data that requires a choice of one thing among a range (Strongly agree--- Strongly disagree..)... should I use the same style of graph? \n\nMany thanks in advance", "c_cnt": 0}, {"subreddit": "datasets", "id": "172suoa", "url": "https://www.reddit.com/r/datasets/comments/172suoa/im_looking_for_an_embedding_fine_tuned_for_tech/", "title": "I'm looking for an embedding fine tuned for tech words.", "post": "The original Bert model gives similarities scores of \n\n- .5736 between vue.js and react\n\n- .6389 between vue.js and k8s\n\nVue.js and react are both frontend frameworks and kubernetes (also called k8s) is a server orchestrator. Therefore it''s odd that the first score is higher than the second. \n\nDo you know of any pretrained model that can catch this type of tech jargon better ?", "c_cnt": 3}, {"subreddit": "datasets", "id": "172dt3k", "url": "https://www.reddit.com/r/datasets/comments/172dt3k/need_help_finding_python_ocr_tool_for_scholarly/", "title": "Need Help finding Python OCR tool for Scholarly PDFs to JSON", "post": "I need to turn a bunch of academic PDFs (with tables) into neat JSON files for data extraction. I\u2019m searching for a Python OCR tool that can: do text and table recognition in scholarly papers; spit out well-structured JSON with the extracted info.\nIf you\u2019ve got recommendations, please let me know! Open-source is awesome, but I\u2019m open to anything that does the job well.\n\nThanks a for your help!", "c_cnt": 6}, {"subreddit": "datasets", "id": "1726vd1", "url": "https://www.reddit.com/r/datasets/comments/1726vd1/where_to_find_open_source_banana_pests_and/", "title": "Where to find open source banana pests and diseases datasets", "post": "Do you guys have access or do you have datasets for banana pest and diseases? Do you mind sharing them with me? I am currently working on a mobile app that can detect pests and diseases in banana plants but I only found very few available ones online. Please help.", "c_cnt": 3}, {"subreddit": "datasets", "id": "17266w2", "url": "https://www.reddit.com/r/datasets/comments/17266w2/where_would_i_get_data_on_rejected_loans/", "title": "Where would I get data on rejected loans?", "post": "I want to perform analysis on reasons for loan rejection. And specifically need data on number of partial loan offers given. By partial loan I mean, if an individual requested for $100 and they get $80.\n\nAny good sources or methods to access/collect the data is appreciated.", "c_cnt": 3}, {"subreddit": "datasets", "id": "171y0lx", "url": "https://www.reddit.com/r/datasets/comments/171y0lx/potential_equivalents_for_twitter_and_reddit_apis/", "title": "Potential equivalents for Twitter and Reddit APIs", "post": "Dear Dear Data People!\n\nNow that Twitter and Reddit APIs are paywalled and pretty much unaffordable for amateur projects, are there some other good social network APIs that you can use for similar projects? I'm quite into NLP and always thought of these two APIs as a steady option for experiments, it's really devastating to see them go.\n\nCheers!", "c_cnt": 0}, {"subreddit": "datasets", "id": "3bxlg7", "url": "https://www.reddit.com/r/datasets/comments/3bxlg7/i_have_every_publicly_available_reddit_comment/", "title": "I have every publicly available Reddit comment for research. ~ 1.7 billion comments @ 250 GB compressed. Any interest in this?", "post": "I am currently doing a massive analysis of Reddit's entire publicly available comment dataset.  The dataset is ~1.7 billion JSON objects complete with the comment, score, author, subreddit, position in comment tree and other fields that are available through Reddit's API.  \n\nI'm currently doing NLP analysis and also putting the entire dataset into a large searchable database using Sphinxsearch (also testing ElasticSearch).  \n\nThis dataset is over 1 terabyte uncompressed, so this would be best for larger research projects.  If you're interested in a sample month of comments, that can be arranged as well.  I am trying to find a place to host this large dataset -- I'm reaching out to Amazon since they have open data initiatives.\n\n**EDIT:  ~~I'm putting up a Digital Ocean box with 2 TB of bandwidth and will throw an entire months worth of comments up (~ 5 gigs compressed)~~  It's now a torrent.  This will give you guys an opportunity to examine the data.  The file is structured with JSON blocks delimited by new lines (\\n).**\n\n**____________________________________________________**\n\nOne month of comments is now available here:\n\n**Download Link:** [Torrent](https://mega.nz/#!ysBWXRqK!yPXLr25PgJi184pbJU3GtnqUY4wG7YvuPpxJjEmnb9A)\n\n**Direct Magnet File:** magnet:?xt=urn:btih:32916ad30ce4c90ee4c47a95bd0075e44ac15dd2&dn=RC%5F2015-01.bz2&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80&tr=udp%3A%2F%2Fopen.demonii.com%3A1337&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969\n\n**Tracker:** udp://tracker.openbittorrent.com:80\n\n**Total Comments:** 53,851,542\n\n**Compression Type:** bzip2 *(5,452,413,560 bytes compressed | 31,648,374,104 bytes uncompressed)*\n\n**md5:** a3fc3d9db18786e4486381a7f37d08e2  RC_2015-01.bz2\n\n**____________________________________________________**\n\n**Example JSON Block:**\n\n    {\"gilded\":0,\"author_flair_text\":\"Male\",\"author_flair_css_class\":\"male\",\"retrieved_on\":1425124228,\"ups\":3,\"subreddit_id\":\"t5_2s30g\",\"edited\":false,\"controversiality\":0,\"parent_id\":\"t1_cnapn0k\",\"subreddit\":\"AskMen\",\"body\":\"I can't agree with passing the blame, but I'm glad to hear it's at least helping you with the anxiety. I went the other direction and started taking responsibility for everything. I had to realize that people make mistakes including myself and it's gonna be alright. I don't have to be shackled to my mistakes and I don't have to be afraid of making them. \",\"created_utc\":\"1420070668\",\"downs\":0,\"score\":3,\"author\":\"TheDukeofEtown\",\"archived\":false,\"distinguished\":null,\"id\":\"cnasd6x\",\"score_hidden\":false,\"name\":\"t1_cnasd6x\",\"link_id\":\"t3_2qyhmp\"}\n\n\n**UPDATE (Saturday 2015-07-03 13:26 ET)**\n\nI'm getting a huge response from this and won't be able to immediately reply to everyone.  I am pinging some people who are helping.  There are two major issues at this point.  Getting the data from my local system to wherever and figuring out bandwidth (since this is a very large dataset).  Please keep checking for new updates.  I am working to make this data publicly available ASAP.  If you're a larger organization or university and have the ability to help seed this initially (will probably require 100 TB of bandwidth to get it rolling), please let me know.  If you can agree to do this, I'll give your organization priority over the data first.\n\n**UPDATE 2 (15:18)**\n\nI've purchased a seedbox.  I'll be updating the link above to the sample file.  Once I can get the full dataset to the seedbox, I'll post the torrent and magnet link to that as well.  I want to thank /u/hak8or for all his help during this process.  It's been a while since I've created torrents and he has been a huge help with explaining how it all works.  Thanks man!\n\n**UPDATE 3 (21:09)**\n\nI'm creating the complete torrent.  There was an issue with my seedbox not allowing public trackers for uploads, so I had to create a private tracker.  I should have a link up shortly to the massive torrent.  I would really appreciate it if people at least seed at 1:1 ratio -- and if you can do more, that's even better!  The size looks to be around ~160 GB -- a bit less than I thought.\n\n**UPDATE 4 (00:49 July 4)**\n\nI'm retiring for the evening.  I'm currently seeding the entire archive to two seedboxes plus two other people.  I'll post the link tomorrow evening once the seedboxes are at 100%.  This will help prevent choking the upload from my home connection if too many people jump on at once.  The seedboxes upload at around 35MB a second in the best case scenario.  We should be good tomorrow evening when I post it.  Happy July 4'th to my American friends!\n\n**UPDATE 5 (14:44)**\n\nSend more beer!  The seedboxes are around 75% and should be finishing up within the next 8 hours.  My next update before I retire for the night will be a magnet link to the main archive.  Thanks!\n\n**UPDATE 6 (20:17)**\n\n**This is the update you've been waiting for!**\n\nThe **entire** archive:  \n\n    magnet:?xt=urn:btih:7690f71ea949b868080401c749e878f98de34d3d&dn=reddit%5Fdata&tr=http%3A%2F%2Ftracker.pushshift.io%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80\n\nPlease seed!\n\n**UPDATE 7 (July 11 14:19)**\n\nUser /u/fhoffa has done a lot of great work making this data available within Google's BigQuery.   Please check out this link for more information:   /r/bigquery/comments/3cej2b/17_billion_reddit_comments_loaded_on_bigquery/\n\nAwesome work!\n\n", "c_cnt": 241}, {"subreddit": "datasets", "id": "lsnml4", "url": "https://www.importyeti.com", "title": "I spent the last 8 months during lockdown pouring my soul into a website that allows you to visualize virtually every U.S. company's international supply chain. E.x. What products, how much, which factories and where does Lululemon import from? (Just type a company in the search box)", "post": "", "c_cnt": 17}, {"subreddit": "datasets", "id": "exnzrd", "url": "https://www.reddit.com/r/datasets/comments/exnzrd/coronavirus_datasets/", "title": "Coronavirus Datasets", "post": "You have probably seen most of these, but I thought I'd share anyway:\n\n**Spreadsheets and Datasets:**\n\n* [https://www.worldometers.info/coronavirus/](https://www.worldometers.info/coronavirus/)\n* [John Hopkins University Github](https://github.com/CSSEGISandData/2019-nCoV) confirmed case numbers.\n* [Google Sheets From DXY.cn](https://docs.google.com/spreadsheets/d/1jS24DjSPVWa4iuxuD4OAXrE3QeI8c9BC1hSlqr-NMiU/edit#gid=1187587451) (Contains some patient information \\[age,gender,etc\\] )\n* [Kaggle Dataset](https://www.kaggle.com/sudalairajkumar/novel-corona-virus-2019-dataset)\n* [Strain Data](https://github.com/nextstrain/ncov) repo\n* [https://covid2019.app/](https://covid2019.app/)  (Google Sheets, thanks /u/supertyler)\n* [ECDC](https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide) (Daily Spreadsheets, Thanks /u/n3ongrau)\n\n**Other Good sources:**\n\n* [BNO](https://bnonews.com/index.php/2020/02/the-latest-coronavirus-cases/) Seems to have latest number w/ sources. (scrape)\n* [What we can find out on a Bioinformatics Level](https://innophore.com/2019-ncov/)\n* [DXY.cn Chinese online community for Medical Professionals](https://ncov.dxy.cn/ncovh5/view/pneumonia) \\*translate page.\n* [John Hopkins University Live Map](https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6)\n* [Mutations](https://nextstrain.org/ncov) (thanks /u/Mynewestaccount34578)\n* [Protein Data Bank File](https://3dprint.nih.gov/discover/3DPX-012867)\n* [Early Transmission Dynamics](https://www.nejm.org/doi/full/10.1056/NEJMoa2001316) Provides statistics on the early cases, median age, gender etc.\n\n**\\[IMPORTANT UPDATE:** *From February 12th the definition of confirmed cases has changed in Hubei, and now includes those who have been clinically diagnosed. Previously China's confirmed cases only included those tested for* [*SARS-CoV-2*](https://en.wikipedia.org/wiki/2019_novel_coronavirus)*. Many datasets will show a spike on that date*.\\]\n\n**There have been a bunch of great comments with links to further resources below!**  \n\\[Last Edit: 15/03/2020\\] ", "c_cnt": 183}, {"subreddit": "datasets", "id": "7eo14t", "url": "https://www.battleforthenet.com/?utm_source=AN&utm_medium=email&utm_campaign=BFTNCallTool&utm_content=voteannouncement&ref=fftf_fftfan1120_30&link_id=0&can_id=185bf77ffd26b044bcbf9d7fadbab34e&email_referrer=email_265020&email_subject=net-neutrality-dies-in-one-month-unless-we-stop-it", "title": "Imagine having to pay extra to download or share datasets. Save net neutrality!", "post": "", "c_cnt": 9}, {"subreddit": "datasets", "id": "9d8k9f", "url": "https://www.blog.google/products/search/making-it-easier-discover-datasets/", "title": "Google releases Dataset Search: \"Similar to how Google Scholar works, Dataset Search lets you find datasets wherever they\u2019re hosted\"", "post": "", "c_cnt": 9}, {"subreddit": "datasets", "id": "excg1h", "url": "https://www.reddit.com/r/datasets/comments/excg1h/congrats_web_scraping_is_legal_us_precedent/", "title": "Congrats! Web scraping is legal! (US precedent)", "post": " Disputes about whether web scraping is legal have been going on for a long time. And now, a couple of months ago, the scandalous case of web scraping between hiQ v. LinkedIn was completed.\n\nYou can read about the progress of the case here: [US court fully legalized website scraping and technically prohibited it.](https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/)\n\nFinally, the court concludes: \"Giving companies like LinkedIn the freedom to decide who can collect and use data \u2013 data that companies do not own, that is publicly available to everyone, and that these companies themselves collect and use \u2013 creates a risk of information monopolies that will violate the public interest\u201d.", "c_cnt": 29}, {"subreddit": "datasets", "id": "cjdxhz", "url": "https://www.reddit.com/r/datasets/comments/cjdxhz/metadata_for_26_million_pornhub_videos_spanning/", "title": "Metadata for 2.6 million Pornhub videos spanning 320k playlists", "post": "I scraped metadata for 2.6M pornhub videos based on the 320k most recently updated playlists as of mid-July 2019. In total, the data is 350MB in compressed json form, separated into playlist, video, and matching/cross-referencing files. They're directly downloadable from these links:\n\n[https://datahub.io/racydata/final/r/dfp.json.gz](https://datahub.io/racydata/final/r/dfp.json.gz) (14MB)\n\n[https://datahub.io/racydata/final/r/dfv.json.gz](https://datahub.io/racydata/final/r/dfv.json.gz) (120MB)\n\n[https://datahub.io/racydata/final/r/dfm.json.gz](https://datahub.io/racydata/final/r/dfm.json.gz) (210MB)\n\n&#x200B;\n\nAnd here's an example jupyter notebook that uses the matching data (40 million pairs of (videoid,playlistid)) to make a sparse matrix with dimensions of (number of unique videos x number of playlists) and reduce the dimensionality with SVD. Then you can get \"recommendations\" for playlists/videos similar to a particular playlist/video based on the distance in this reduced dimensional space.\n\n[https://gist.github.com/racydata/92ae85ea47da7c2d0bf50442bb0e83ea](https://gist.github.com/racydata/92ae85ea47da7c2d0bf50442bb0e83ea)\n\nThe notebook also shows what columns you can play with in those three files.", "c_cnt": 15}, {"subreddit": "datasets", "id": "oybg5f", "url": "https://www.reddit.com/r/datasets/comments/oybg5f/all_digitized_texas_appeals_court_cases_since/", "title": "All Digitized Texas Appeals Court Cases Since 1900 - 12GB - 696,036 cases", "post": "[Kaggle dataset page](https://www.kaggle.com/judyrecords/all-digitized-texas-appeals-court-cases-since-1900?select=TxAppeals_Case_schema_mysql.sql)\n\nScope of Data\n\n* All electronically-available Texas Appeals Court cases filed since 1900 (as of 2021-08-01).\n* Courts included: Texas Supreme Court, Court of Criminal Appeals, 14 Appeals Courts (regional)\n* Total cases: 696,036.\n* Full dataset approx 12GB.\n* Sample dataset approx 10MB.\n* Download 500 sample rows or full dataset -- in either SQL or JSON format.\n* Data source: [https://search.txcourts.gov/CaseSearch.aspx?coa=cossup](https://search.txcourts.gov/CaseSearch.aspx?coa=cossup)\n* Aggregated by: [https://www.judyrecords.com](https://www.judyrecords.com/)\n* Parsed fields include caseId, createdAt (Unix timestamp), siteCaseNum, courtKey, and httpReq.\n* Detailed case information is not parsed within each case currently, but can be parsed from standardized HTML structure.\n* Sample case from data source: [https://search.txcourts.gov/Case.aspx?cn=01-20-00103-CV&coa=coa01](https://search.txcourts.gov/Case.aspx?cn=01-20-00103-CV&coa=coa01)\n* Court structure of Texas: [https://www.txcourts.gov/media/1452084/court-structure-chart-february-2021.pdf](https://www.txcourts.gov/media/1452084/court-structure-chart-february-2021.pdf)\n\nCase Count by Court\n\n|Court|Case Count|Court Key|\n|:-|:-|:-|\n|Texas Supreme Court|65,945|cossup|\n|Texas Court of Criminal Appeals|242,915|coscca|\n|Texas Court of Appeals #1|46,663|coa01|\n|Texas Court of Appeals #2|34,458|coa02|\n|Texas Court of Appeals #3|24,629|coa03|\n|Texas Court of Appeals #4|33,469|coa04|\n|Texas Court of Appeals #5|69,112|coa05|\n|Texas Court of Appeals #6|12,206|coa06|\n|Texas Court of Appeals #7|17,136|coa07|\n|Texas Court of Appeals #8|16,180|coa08|\n|Texas Court of Appeals #9|18,710|coa09|\n|Texas Court of Appeals #10|14,550|coa10|\n|Texas Court of Appeals #11|13,058|coa11|\n|Texas Court of Appeals #12|14,366|coa12|\n|Texas Court of Appeals #13|26,440|coa13|\n|Texas Court of Appeals #14|46,199|coa14|\n\n&#x200B;", "c_cnt": 4}, {"subreddit": "datasets", "id": "gyfbb0", "url": "https://docs.google.com/spreadsheets/d/1ahA7I9uzEq5heyTUDsjR2OI_442P8_p83DmMUp4ItSc/edit#gid=1526202549", "title": "Protests engaging 3.5% of a population rarely fail", "post": "", "c_cnt": 25}, {"subreddit": "datasets", "id": "kzh789", "url": "https://www.kaggle.com/arnavsharmaas/all-donald-trump-transcripts", "title": "Since I didn't see anything else good in Kaggle, I scraped all of Trump's speeches(~3.4 Million characters) and put it all in a single txt file", "post": "", "c_cnt": 29}]

Reddit Summary:
Topic: Cool geology datasets
Subreddit: r/geology
Post: The poster, a stats major, is seeking a cool geology dataset for their final project. They are confident in their data analysis skills and hope to enhance their resume.
Comment Summary:
- Suggestions for research topics include volcanism, oil fields, and environmental spills.
- A dataset on historical oil and gas well drilling data in Pennsylvania dating back to 1800 is mentioned, but no link is provided.
- The poster's class covers sinkholes, rock formations, and rising sea levels, but they are open to any interesting findings.
- The poster is particularly interested in data from Florida, but reliable findings from anywhere in the US are acceptable.
- Sources for geology datasets are suggested, such as the USGS data releases and the Florida Department of Environmental Protection website.
References:
- https://www.usgs.gov/products/data/data-releases
- https://floridadep.gov/fgs/data-maps

